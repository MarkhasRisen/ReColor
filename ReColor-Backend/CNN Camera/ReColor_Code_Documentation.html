<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ReColor Backend Code Documentation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-top: 30px;
        }
        
        h2 {
            color: #34495e;
            border-bottom: 2px solid #95a5a6;
            padding-bottom: 8px;
            margin-top: 25px;
        }
        
        h3 {
            color: #2980b9;
            margin-top: 20px;
        }
        
        h4 {
            color: #8e44ad;
            margin-top: 15px;
        }
        
        code {
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Consolas', 'Monaco', monospace;
            color: #e74c3c;
        }
        
        pre {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Consolas', 'Monaco', monospace;
            margin: 10px 0;
        }
        
        .code-block {
            background-color: #f8f9fa;
            border-left: 4px solid #3498db;
            padding: 10px 15px;
            margin: 10px 0;
            border-radius: 0 5px 5px 0;
        }
        
        .architecture-diagram {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            text-align: center;
            font-family: monospace;
            margin: 15px 0;
        }
        
        .feature-list {
            background-color: #e8f5e8;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #27ae60;
        }
        
        .warning-box {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
        }
        
        .info-box {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            border-radius: 5px;
            padding: 15px;
            margin: 10px 0;
        }
        
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 15px 0;
        }
        
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        
        th {
            background-color: #3498db;
            color: white;
        }
        
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        
        .toc {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }
        
        .toc ul {
            list-style-type: none;
            padding-left: 20px;
        }
        
        .toc a {
            text-decoration: none;
            color: #3498db;
        }
        
        .performance-metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .metric-card {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #e74c3c;
        }
    </style>
</head>
<body>

<h1>ReColor Backend Code Documentation</h1>

<div class="toc">
<h2>Table of Contents</h2>
<ul>
    <li><a href="#project-overview">1. Project Overview</a></li>
    <li><a href="#architecture">2. Architecture</a></li>
    <li><a href="#core-modules">3. Core Modules</a></li>
    <li><a href="#utility-modules">4. Utility Modules</a></li>
    <li><a href="#demo-and-test-files">5. Demo and Test Files</a></li>
    <li><a href="#file-structure-summary">6. File Structure Summary</a></li>
</ul>
</div>

<h2 id="project-overview">Project Overview</h2>

<p>The <strong>ReColor TensorFlow Colorblind Detection System</strong> is a comprehensive, real-time application designed to detect colors using AI and simulate color vision deficiency (CVD) for accessibility purposes. The system integrates multiple advanced technologies:</p>

<div class="feature-list">
<ul>
    <li><strong>TensorFlow CNN</strong> for intelligent color classification</li>
    <li><strong>K-means clustering</strong> for color analysis and simplification</li>
    <li><strong>Scientific CVD simulation</strong> using transformation matrices</li>
    <li><strong>Real-time camera processing</strong> with GPU acceleration</li>
    <li><strong>Daltonization</strong> for color enhancement</li>
    <li><strong>Comprehensive data logging</strong> for analysis</li>
</ul>
</div>

<h2 id="architecture">Architecture</h2>

<p>The system follows a modular, object-oriented architecture with clear separation of concerns:</p>

<div class="architecture-diagram">
<pre>
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   main.py       │───▶│  recolor_app.py │───▶│ camera_handler. │
│ (Entry Point)   │    │ (Controller)    │    │ py (Display)    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                               │
                               ▼
        ┌─────────────────┬─────────────────┬─────────────────┐
        │                 │                 │                 │
        ▼                 ▼                 ▼                 ▼
┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐
│color_model. │   │colorblind_  │   │color_logger │   │unified_color│
│py (AI)      │   │detector.py  │   │.py (Data)   │   │_pipeline.py │
│             │   │(Simulation) │   │             │   │(Integration)│
└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘
        │                 │                 │                 │
        └─────────────────┴─────────────────┴─────────────────┘
                               │
                               ▼
                        ┌─────────────┐
                        │  utils.py   │
                        │ (Utilities) │
                        └─────────────┘
</pre>
</div>

<h2 id="core-modules">Core Modules</h2>

<h3>1. main.py - Application Entry Point</h3>

<p><strong>Purpose:</strong> Command-line interface and application startup controller</p>

<h4>Key Functions:</h4>
<ul>
    <li><code>create_argument_parser()</code>: Creates comprehensive CLI with 20+ options</li>
    <li><code>setup_logging()</code>: Configures logging levels (debug, verbose, warning)</li>
    <li><code>show_system_info()</code>: Displays system information including GPU, cameras, models</li>
    <li><code>validate_arguments()</code>: Validates user inputs and creates directories</li>
    <li><code>main()</code>: Main entry point orchestrating application startup</li>
</ul>

<div class="code-block">
<h4>Command Line Arguments:</h4>
<pre>
# Camera Settings
--camera ID           # Camera device ID (default: 0)
--width WIDTH         # Frame width (default: 640)
--height HEIGHT       # Frame height (default: 480)
--fps FPS            # Target FPS (default: 30)

# Model Settings
--model PATH         # Pre-trained model weights
--no-auto-train     # Disable synthetic training
--train-samples N   # Training samples per class (default: 500)
--train-epochs N    # Training epochs (default: 20)

# Enhanced Features
--kmeans-clusters N        # K-means clusters (default: 5)
--daltonization-strength F # Enhancement strength (default: 1.5)
--enable-kmeans           # Enable K-means analysis on startup
--enable-daltonization    # Enable color enhancement on startup
--enable-unified-pipeline # Enable full integration pipeline
</pre>
</div>

<div class="info-box">
<h4>Usage Examples:</h4>
<pre>
python main.py --camera 0 --enable-kmeans --daltonization-strength 2.0
python main.py --system-info  # Show detailed system information
</pre>
</div>

<h3>2. recolor_app.py - Main Application Controller</h3>

<p><strong>Purpose:</strong> Central orchestrator coordinating all system components</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>ReColorApp</code>: Main controller class</li>
</ul>

<h4>Core Methods:</h4>
<ul>
    <li><code>initialize(config)</code>: Sets up all components with GPU detection</li>
    <li><code>run()</code>: Main application loop with error handling</li>
    <li><code>shutdown()</code>: Graceful cleanup and resource release</li>
</ul>

<div class="code-block">
<h4>Component Integration:</h4>
<pre>
# Component initialization order:
1. GPU setup and detection
2. ColorModel (TensorFlow CNN)
3. ColorBlindnessSimulator (CVD matrices)
4. CameraHandler (OpenCV management)
5. ColorLogger (CSV data persistence)
6. UnifiedColorPipeline (Integration layer)
</pre>
</div>

<h4>Configuration Management:</h4>
<ul>
    <li>Camera settings (resolution, FPS, device ID)</li>
    <li>AI model parameters (training samples, epochs)</li>
    <li>Enhanced features (K-means, daltonization, unified pipeline)</li>
    <li>Logging and data export settings</li>
</ul>

<h3>3. color_model.py - TensorFlow CNN Color Classification</h3>

<p><strong>Purpose:</strong> AI-powered color recognition using convolutional neural networks</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>ColorModel(tf.Module)</code>: TensorFlow-based CNN for real-time color classification</li>
</ul>

<div class="code-block">
<h4>CNN Architecture:</h4>
<pre>
Input: (64, 64, 3) RGB image patches
├── Conv2D(32, 3x3) → ReLU → MaxPool(2x2)
├── Conv2D(64, 3x3) → ReLU → MaxPool(2x2)  
├── Conv2D(128, 3x3) → ReLU → MaxPool(2x2)
├── Flatten → Dense(128) → ReLU → Dropout(0.5)
└── Dense(9) → Softmax (9 color classes)
</pre>
</div>

<h4>Core Methods:</h4>
<ul>
    <li><code>_build_model()</code>: Constructs lightweight CNN architecture</li>
    <li><code>_compile_model()</code>: Configures optimizer (Adam) and loss (sparse categorical crossentropy)</li>
    <li><code>generate_synthetic_data()</code>: Creates training data with color variations</li>
    <li><code>train_on_synthetic_data()</code>: Trains model on generated dataset</li>
    <li><code>predict_color()</code>: Real-time color prediction with confidence scoring</li>
    <li><code>save_weights()</code> / <code>load_weights()</code>: Model persistence</li>
</ul>

<div class="info-box">
<h4>Color Classes (9 primary colors):</h4>
<code>['Red', 'Green', 'Blue', 'Yellow', 'Orange', 'Purple', 'Pink', 'Brown', 'Gray']</code>
</div>

<h4>Performance Features:</h4>
<ul>
    <li>GPU acceleration with automatic fallback to CPU</li>
    <li>Memory-efficient batch processing</li>
    <li>Real-time inference (&lt;50ms per prediction)</li>
    <li>Confidence scoring for prediction quality assessment</li>
</ul>

<h3>4. colorblind_detector.py - CVD Simulation & Enhancement</h3>

<p><strong>Purpose:</strong> Scientifically accurate color vision deficiency simulation and daltonization</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>CVDType(Enum)</code>: Color vision deficiency types</li>
    <li><code>CVDSeverity(Enum)</code>: Severity levels for anomalous trichromacy</li>
    <li><code>ColorBlindnessSimulator</code>: Main CVD processing class</li>
</ul>

<div class="code-block">
<h4>CVD Types Supported:</h4>
<pre>
# Complete Dichromacy (missing cone type):
PROTANOPIA    # Red-blind (missing L cones)
DEUTERANOPIA  # Green-blind (missing M cones)
TRITANOPIA    # Blue-blind (missing S cones)

# Anomalous Trichromacy (shifted cone sensitivity):
PROTANOMALY   # Red-weak (shifted L cones)
DEUTERANOMALY # Green-weak (shifted M cones)  
TRITANOMALY   # Blue-weak (shifted S cones)
</pre>
</div>

<div class="info-box">
<h4>Scientific Foundation:</h4>
<p>Based on peer-reviewed research by Brettel, Viénot & Mollon (1997) and Machado, Oliveira & Fernandes (2009)</p>
</div>

<div class="code-block">
<h4>Transformation Matrices Example:</h4>
<pre>
# Example: Protanopia (Red-blindness)
PROTANOPIA_MATRIX = [
    [0.170, 0.830, 0.000],  # Red-green confusion
    [0.170, 0.830, 0.000],  # Complete inability to distinguish
    [0.000, 0.000, 1.000]   # Blue perception intact
]
</pre>
</div>

<h4>Core Methods:</h4>
<ul>
    <li><code>simulate_cvd()</code>: Applies CVD transformation to images</li>
    <li><code>daltonize()</code>: Enhances colors for better CVD discrimination</li>
    <li><code>get_ishihara_confusion()</code>: Demonstrates number invisibility in color blindness tests</li>
    <li><code>_apply_transformation_matrix()</code>: Matrix multiplication for color space conversion</li>
</ul>

<div class="warning-box">
<h4>Daltonization Algorithm:</h4>
<ol>
    <li>Simulate CVD perception of original image</li>
    <li>Calculate error between original and simulated</li>
    <li>Redistribute error to perceivable color channels</li>
    <li>Apply enhancement with adjustable strength (0.5x to 3.0x)</li>
</ol>
</div>

<h3>5. camera_handler.py - Real-time Camera Processing</h3>

<p><strong>Purpose:</strong> Webcam capture, real-time display, and user interaction management</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>CameraHandler</code>: OpenCV-based camera management with interactive controls</li>
</ul>

<div class="code-block">
<h4>Real-time Processing Pipeline:</h4>
<pre>
1. Camera capture (OpenCV) → RGB conversion
2. ROI (Region of Interest) extraction for color detection
3. Parallel processing:
   ├── AI color prediction (ColorModel)
   ├── K-means color analysis (optional)
   ├── Image simplification (optional)
   └── CVD simulation & daltonization
4. Overlay rendering (color info, FPS, controls)
5. Display management (side-by-side, full-screen modes)
</pre>
</div>

<table>
<thead>
<tr>
    <th>Key</th>
    <th>Function</th>
    <th>Category</th>
</tr>
</thead>
<tbody>
<tr>
    <td>C</td>
    <td>Capture color and save to CSV</td>
    <td>Basic Controls</td>
</tr>
<tr>
    <td>N</td>
    <td>Cycle CVD types</td>
    <td>Basic Controls</td>
</tr>
<tr>
    <td>P</td>
    <td>Pause/Resume camera feed</td>
    <td>Basic Controls</td>
</tr>
<tr>
    <td>S</td>
    <td>Toggle side-by-side display</td>
    <td>Basic Controls</td>
</tr>
<tr>
    <td>Q</td>
    <td>Quit application</td>
    <td>Basic Controls</td>
</tr>
<tr>
    <td>K</td>
    <td>Toggle K-means color analysis</td>
    <td>Enhanced Features</td>
</tr>
<tr>
    <td>M</td>
    <td>Toggle K-means image simplification</td>
    <td>Enhanced Features</td>
</tr>
<tr>
    <td>D</td>
    <td>Toggle daltonization</td>
    <td>Enhanced Features</td>
</tr>
<tr>
    <td>U</td>
    <td>Toggle unified pipeline</td>
    <td>Enhanced Features</td>
</tr>
<tr>
    <td>1/2</td>
    <td>Adjust K-means clusters</td>
    <td>Adjustments</td>
</tr>
<tr>
    <td>3/4</td>
    <td>Adjust daltonization strength</td>
    <td>Adjustments</td>
</tr>
</tbody>
</table>

<h4>Core Methods:</h4>
<ul>
    <li><code>initialize_camera()</code>: OpenCV camera setup with error handling</li>
    <li><code>capture_and_process_frame()</code>: Main processing loop</li>
    <li><code>handle_keyboard_input()</code>: Real-time control processing</li>
    <li><code>render_color_info_overlay()</code>: Information display rendering</li>
    <li><code>create_side_by_side_display()</code>: Comparison view generation</li>
    <li><code>cleanup()</code>: Resource cleanup and camera release</li>
</ul>

<h4>Performance Optimization:</h4>
<ul>
    <li>Threaded camera capture for smooth FPS</li>
    <li>Efficient ROI processing (center region only)</li>
    <li>GPU-accelerated image transformations</li>
    <li>Real-time FPS monitoring and adjustment</li>
</ul>

<h3>6. color_logger.py - Data Persistence & Analytics</h3>

<p><strong>Purpose:</strong> Comprehensive CSV logging with session tracking and statistical analysis</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>ColorLogger</code>: Data persistence and session management</li>
</ul>

<div class="code-block">
<h4>CSV Data Structure:</h4>
<pre>
timestamp,session_id,color_name_rgb,color_name_ai,rgb_r,rgb_g,rgb_b,
hex_color,ai_confidence,cvd_type,x_position,y_position,frame_width,
frame_height,dominant_colors,color_percentages,session_time_elapsed
</pre>
</div>

<h4>Core Methods:</h4>
<ul>
    <li><code>start_session()</code>: Creates new session with unique ID</li>
    <li><code>log_color_capture()</code>: Records color data with full metadata</li>
    <li><code>end_session()</code>: Finalizes session with statistics</li>
    <li><code>export_to_json()</code>: Structured data export for analysis</li>
    <li><code>get_session_statistics()</code>: Comprehensive analytics</li>
</ul>

<div class="feature-list">
<h4>Session Analytics:</h4>
<ul>
    <li>Total captures per session</li>
    <li>Color frequency distribution</li>
    <li>AI confidence averages</li>
    <li>CVD type usage patterns</li>
    <li>Temporal analysis (captures over time)</li>
    <li>Dominant color trends</li>
</ul>
</div>

<h4>Data Export Formats:</h4>
<ul>
    <li><strong>CSV</strong>: Real-time logging for spreadsheet analysis</li>
    <li><strong>JSON</strong>: Structured export for programmatic processing</li>
    <li><strong>Statistics Summary</strong>: Session-based analytics reports</li>
</ul>

<h3>7. unified_color_pipeline.py - Advanced Integration</h3>

<p><strong>Purpose:</strong> Seamless integration of K-means clustering, CNN classification, and daltonization</p>

<h4>Key Classes:</h4>
<ul>
    <li><code>UnifiedColorPipeline</code>: Three-stage processing integration</li>
</ul>

<div class="code-block">
<h4>Pipeline Architecture:</h4>
<pre>
# Stage 1: K-Means Color Family Grouping
Input Frame → Pixel sampling → K-means clustering → Color families

# Stage 2: CNN Classification within Families  
Color families → Patch extraction → CNN prediction → Refined classification

# Stage 3: Enhanced Frame Generation + Daltonization
Family smoothing + CNN details → Enhanced frame → CVD daltonization → Output
</pre>
</div>

<div class="info-box">
<h4>8 Predefined Color Families:</h4>
<ul>
    <li><strong>Red Family</strong> (0-30°) - Reds, crimsons, scarlets</li>
    <li><strong>Orange Family</strong> (30-60°) - Oranges, amber, coral</li>
    <li><strong>Yellow Family</strong> (60-90°) - Yellows, gold, cream</li>
    <li><strong>Green Family</strong> (90-150°) - Greens, lime, olive</li>
    <li><strong>Cyan Family</strong> (150-210°) - Cyans, teal, turquoise</li>
    <li><strong>Blue Family</strong> (210-270°) - Blues, navy, azure</li>
    <li><strong>Purple Family</strong> (270-330°) - Purples, violet, indigo</li>
    <li><strong>Pink Family</strong> (330-360°) - Pinks, rose, magenta</li>
</ul>
</div>

<div class="performance-metrics">
<div class="metric-card">
    <h4>Performance Tracking:</h4>
    <ul>
        <li>K-means processing time (ms)</li>
        <li>CNN inference time (ms)</li>
        <li>Daltonization processing time (ms)</li>
        <li>Total pipeline time (ms)</li>
        <li>Effective FPS calculation</li>
        <li>Memory usage monitoring</li>
    </ul>
</div>
</div>

<h4>Core Methods:</h4>
<ul>
    <li><code>process_frame()</code>: Main pipeline processing with error handling</li>
    <li><code>_extract_color_families()</code>: K-means clustering with adaptive cluster adjustment</li>
    <li><code>_classify_colors_with_cnn()</code>: CNN processing within color families</li>
    <li><code>_create_enhanced_frame()</code>: Intelligent blending of K-means and CNN results</li>
    <li><code>get_pipeline_summary()</code>: Comprehensive performance and configuration analytics</li>
</ul>

<div class="feature-list">
<h4>Integration Benefits:</h4>
<ol>
    <li><strong>Reduced Noise</strong>: K-means smooths color variations before CNN processing</li>
    <li><strong>Improved Accuracy</strong>: CNN provides precise classification within similar color groups</li>
    <li><strong>Enhanced Performance</strong>: Targeted CNN processing only where needed</li>
    <li><strong>Better Enhancement</strong>: Daltonization works on cleaner, classified color data</li>
</ol>
</div>

<h2 id="utility-modules">Utility Modules</h2>

<h3>utils.py - Core Utilities & Helper Functions</h3>

<p><strong>Purpose:</strong> Essential utility functions for color processing, GPU management, and common operations</p>

<h4>GPU Management:</h4>
<ul>
    <li><code>setup_gpu()</code>: Automatic GPU detection, memory configuration, and fallback handling</li>
    <li>Configures TensorFlow GPU memory growth to prevent allocation issues</li>
    <li>Returns comprehensive GPU information (name, memory, compute capability)</li>
</ul>

<div class="code-block">
<h4>Color Processing Functions:</h4>
<pre>
# Color Conversion & Analysis:
rgb_to_hex()           # RGB to hexadecimal conversion
hex_to_rgb()           # Hexadecimal to RGB conversion  
rgb_to_hsv()           # RGB to HSV color space conversion
get_color_name()       # Intelligent color naming using distance algorithms
get_dominant_color()   # Extract single dominant color (mean/median methods)
clamp_rgb()            # Ensure RGB values stay within 0-255 range

# K-means Color Analysis:
extract_dominant_colors_kmeans()  # Extract 5-15 dominant colors with percentages
simplify_image_kmeans()          # Image posterization using K-means
analyze_color_distribution()     # Comprehensive color diversity analysis
</pre>
</div>

<h4>Advanced K-means Features:</h4>
<ul>
    <li><strong>Adaptive Clustering</strong>: Automatically adjusts cluster count based on unique colors</li>
    <li><strong>Performance Optimization</strong>: Pixel sampling for real-time processing (10% sample ratio)</li>
    <li><strong>Warning Suppression</strong>: Eliminates convergence warnings for single-color images</li>
    <li><strong>Statistical Analysis</strong>: Color percentages, diversity metrics, dominance calculations</li>
</ul>

<div class="code-block">
<h4>Utility Functions:</h4>
<pre>
# Image Processing:
create_color_swatch()     # Generate color preview rectangles
resize_image_aspect()     # Aspect-ratio preserving resize
apply_gaussian_blur()     # Noise reduction for color detection

# Data Formatting:
format_timestamp()        # Standardized timestamp formatting
ensure_directory_exists() # Safe directory creation
clamp_value()            # Generic value clamping function
</pre>
</div>

<h4>Error Handling:</h4>
<ul>
    <li>Comprehensive try-catch blocks with logging</li>
    <li>Graceful fallbacks for failed operations</li>
    <li>Memory-efficient processing for large images</li>
</ul>

<h2 id="demo-and-test-files">Demo and Test Files</h2>

<h3>pipeline_demo.py - Pipeline Demonstration</h3>

<p><strong>Purpose:</strong> Comprehensive demonstration of the Unified Color Processing Pipeline</p>

<h4>Key Functions:</h4>
<ul>
    <li><code>create_test_image()</code>: Generates multi-color test image with 13 distinct regions</li>
    <li><code>demonstrate_pipeline()</code>: Shows complete pipeline processing stages</li>
    <li><code>visualize_results()</code>: Creates comparison plots of pipeline stages</li>
</ul>

<div class="code-block">
<h4>Demonstration Flow:</h4>
<pre>
1. Create test image with varied colors and realistic noise
2. Process through unified pipeline (K-means→CNN→Daltonization)
3. Display intermediate results:
   ├── Original image
   ├── K-means color families
   ├── CNN classifications overlay
   ├── Enhanced frame
   └── Daltonized result for different CVD types
4. Generate performance statistics and processing time analysis
</pre>
</div>

<h4>Educational Value:</h4>
<ul>
    <li>Shows pipeline integration in action</li>
    <li>Demonstrates performance benefits of combined approach</li>
    <li>Provides visual comparison of processing stages</li>
    <li>Validates scientific accuracy of CVD simulation</li>
</ul>

<h3>tinsarplow.py - GPU Verification</h3>

<p><strong>Purpose:</strong> Simple TensorFlow GPU detection and verification</p>

<h4>Functions:</h4>
<ul>
    <li>Displays TensorFlow version information</li>
    <li>Lists available GPU devices</li>
    <li>Verifies CUDA installation and GPU accessibility</li>
</ul>

<p><strong>Usage:</strong> Quick system verification before running main application</p>

<h2 id="file-structure-summary">File Structure Summary</h2>

<h3>Configuration & Setup Files</h3>
<ul>
    <li><strong>requirements.txt</strong>: Python dependencies with exact versions for reproducibility</li>
    <li><strong>README.md</strong>: Comprehensive documentation with installation and usage instructions</li>
    <li><strong>UNIFIED_PIPELINE_COMPLETE.md</strong>: Detailed pipeline documentation</li>
</ul>

<div class="code-block">
<h3>Directory Structure</h3>
<pre>
ReColor-Backend/
├── Core Application Files
│   ├── main.py                    # Entry point & CLI
│   ├── recolor_app.py            # Main controller
│   ├── color_model.py            # TensorFlow CNN
│   ├── colorblind_detector.py    # CVD simulation
│   ├── camera_handler.py         # Real-time processing
│   ├── color_logger.py           # Data persistence
│   ├── unified_color_pipeline.py # Advanced integration
│   └── utils.py                  # Utility functions
├── Demo & Testing
│   ├── pipeline_demo.py          # Pipeline demonstration
│   └── tinsarplow.py            # GPU verification
├── Data & Models
│   ├── models/                   # Saved TensorFlow weights
│   └── logs/                     # CSV data logs
└── Dependencies
    ├── requirements.txt          # Python packages
    └── zlibwapi.dll             # Windows TensorFlow fix
</pre>
</div>

<div class="code-block">
<h3>Key Dependencies</h3>
<pre>
# Core ML & Computer Vision:
tensorflow==2.10.0          # AI model framework
opencv-python==4.6.0.66     # Camera and image processing
numpy==1.23.5               # Numerical computations
scikit-learn==1.1.3        # K-means clustering

# Scientific Computing:
scipy==1.9.3               # Advanced mathematics
matplotlib==3.6.2          # Visualization and plotting
pandas==1.5.2              # Data analysis and CSV handling

# System & Performance:
psutil==5.9.4              # System monitoring
</pre>
</div>

<h2>Technical Innovations</h2>

<h3>1. Adaptive K-means Clustering</h3>
<ul>
    <li><strong>Problem</strong>: K-means convergence warnings with insufficient unique colors</li>
    <li><strong>Solution</strong>: Dynamic cluster adjustment based on image color diversity</li>
    <li><strong>Impact</strong>: Eliminates warnings, improves performance, maintains accuracy</li>
</ul>

<h3>2. Hybrid CNN-K-means Integration</h3>
<ul>
    <li><strong>Innovation</strong>: K-means pre-processing followed by targeted CNN classification</li>
    <li><strong>Benefits</strong>: Reduced noise, improved accuracy, optimized performance</li>
    <li><strong>Result</strong>: Best of both worlds - clustering speed with CNN precision</li>
</ul>

<h3>3. Real-time Daltonization Pipeline</h3>
<ul>
    <li><strong>Challenge</strong>: Complex color enhancement in real-time</li>
    <li><strong>Solution</strong>: GPU-accelerated matrix operations with adjustable strength</li>
    <li><strong>Achievement</strong>: 30+ FPS daltonization with scientific accuracy</li>
</ul>

<h3>4. Comprehensive Session Analytics</h3>
<ul>
    <li><strong>Feature</strong>: Detailed logging with statistical analysis</li>
    <li><strong>Data</strong>: Color trends, AI confidence, CVD usage patterns, temporal analysis</li>
    <li><strong>Value</strong>: Research-grade data collection for color vision studies</li>
</ul>

<h2>Performance Characteristics</h2>

<h3>System Requirements</h3>
<ul>
    <li><strong>Minimum</strong>: Python 3.8+, 4GB RAM, integrated graphics</li>
    <li><strong>Recommended</strong>: Python 3.10+, 8GB RAM, NVIDIA GPU with CUDA</li>
    <li><strong>Optimal</strong>: RTX 4050+ GPU, 16GB RAM, SSD storage</li>
</ul>

<div class="performance-metrics">
<div class="metric-card">
    <h4>Real-time Performance</h4>
    <ul>
        <li>Frame Rate: 30+ FPS (GPU) / 10-15 FPS (CPU)</li>
        <li>AI Inference: &lt;50ms per prediction</li>
        <li>K-means: &lt;30ms per frame (with sampling)</li>
        <li>Daltonization: &lt;20ms per frame</li>
        <li>Total Latency: &lt;100ms end-to-end</li>
    </ul>
</div>

<div class="metric-card">
    <h4>Memory Usage</h4>
    <ul>
        <li>Application: ~100MB RAM</li>
        <li>TensorFlow Model: ~50MB VRAM</li>
        <li>Image Processing: ~200MB peak</li>
    </ul>
</div>
</div>

<h3>Scalability</h3>
<ul>
    <li><strong>Resolution</strong>: Supports 480p to 1080p real-time processing</li>
    <li><strong>Multiple Cameras</strong>: Architecture supports multiple camera streams</li>
    <li><strong>Batch Processing</strong>: Can process video files and image sequences</li>
    <li><strong>Platform</strong>: Windows (primary), Linux/macOS (compatible)</li>
</ul>

<h2>Development Architecture Principles</h2>

<h3>1. Modular Design</h3>
<ul>
    <li><strong>Single Responsibility</strong>: Each class has one clear purpose</li>
    <li><strong>Loose Coupling</strong>: Components interact through well-defined interfaces</li>
    <li><strong>High Cohesion</strong>: Related functionality grouped logically</li>
</ul>

<h3>2. Error Resilience</h3>
<ul>
    <li><strong>Graceful Degradation</strong>: System continues operating with reduced functionality</li>
    <li><strong>Comprehensive Logging</strong>: Detailed error tracking and debugging information</li>
    <li><strong>Resource Management</strong>: Proper cleanup and memory management</li>
</ul>

<h3>3. Performance Optimization</h3>
<ul>
    <li><strong>GPU Acceleration</strong>: Automatic GPU detection and utilization</li>
    <li><strong>Efficient Algorithms</strong>: Optimized processing pipelines</li>
    <li><strong>Memory Management</strong>: Careful memory usage and garbage collection</li>
</ul>

<h3>4. Extensibility</h3>
<ul>
    <li><strong>Plugin Architecture</strong>: Easy addition of new CVD types or enhancement algorithms</li>
    <li><strong>Configuration-driven</strong>: Behavior controlled through parameters</li>
    <li><strong>API Design</strong>: Clear interfaces for integration with other systems</li>
</ul>

<div class="info-box">
<p>This documentation provides a comprehensive overview of the ReColor backend codebase, its architecture, and implementation details. Each module is designed to work independently while contributing to the overall system's functionality of providing real-time, scientifically accurate color vision analysis and accessibility enhancement.</p>
</div>

</body>
</html>